{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 설정\n",
    "WIDTH, HEIGHT = 800, 600\n",
    "WHITE, BLACK, BLUE, YELLOW = (255, 255, 255), (0, 0, 0), (0, 0, 255), (255, 255, 0)\n",
    "PADDLE_WIDTH, PADDLE_HEIGHT, PADDLE_SPEED = 100, 20, 10\n",
    "BALL_RADIUS, BALL_SPEED_X, BALL_SPEED_Y = 10, 5, 5\n",
    "BRICK_WIDTH, BRICK_HEIGHT, BRICK_ROWS, BRICK_COLS, BRICK_SPACING = 100, 30, 5, 8, 10\n",
    "\n",
    "# 게임 초기화\n",
    "pygame.init()\n",
    "screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "pygame.display.set_caption(\"Breakout\")\n",
    "clock = pygame.time.Clock()\n",
    "font = pygame.font.Font(None, 36)\n",
    "\n",
    "# Deep Q-Network 모델 정의\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 16)\n",
    "        self.fc2 = nn.Linear(16, 32)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.fc4 = nn.Linear(16, 8)\n",
    "        self.fc5 = nn.Linear(8, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "# DQN 에이전트 정의\n",
    "class DQNAgent:\n",
    "    def __init__(self, input_size, output_size, gamma=0.99, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.995):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.memory = deque()\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.model = DQN(input_size, output_size)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.output_size)\n",
    "        q_values = self.model(torch.tensor(state, dtype=torch.float32))\n",
    "        return torch.argmax(q_values).item()\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            if not done:\n",
    "                target = reward + self.gamma * torch.max(self.model(torch.tensor(next_state, dtype=torch.float32))).item()\n",
    "            else:\n",
    "                target = reward\n",
    "            target_f = self.model(torch.tensor(state, dtype=torch.float32)).clone().detach()\n",
    "            target_f[action] = target\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = nn.MSELoss()(self.model(torch.tensor(state, dtype=torch.float32)), target_f)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "# 게임 환경 클래스 정의\n",
    "class Breakout:\n",
    "    def __init__(self):\n",
    "        self.paddle = pygame.Rect((WIDTH - PADDLE_WIDTH) // 2, HEIGHT - PADDLE_HEIGHT - 10, PADDLE_WIDTH, PADDLE_HEIGHT)\n",
    "        self.ball = pygame.Rect(WIDTH // 2 - BALL_RADIUS, HEIGHT // 2 - BALL_RADIUS, BALL_RADIUS * 2, BALL_RADIUS * 2)\n",
    "        self.bricks = [pygame.Rect(j * (BRICK_WIDTH + BRICK_SPACING), i * (BRICK_HEIGHT + BRICK_SPACING) + 50, BRICK_WIDTH, BRICK_HEIGHT)\n",
    "                       for i in range(BRICK_ROWS) for j in range(BRICK_COLS)]\n",
    "        self.ball_speed_x = BALL_SPEED_X * random.choice([1, -1])\n",
    "        self.ball_speed_y = BALL_SPEED_Y * random.choice([1, -1])\n",
    "        self.agent = DQNAgent(input_size=6, output_size=2)\n",
    "\n",
    "    def get_state(self):\n",
    "        state = [self.ball.centerx, \n",
    "                self.ball.centery, \n",
    "                self.ball_speed_x, \n",
    "                self.ball_speed_y,\n",
    "                self.paddle.topleft[0], \n",
    "                self.paddle.topright[0]]\n",
    "        return state\n",
    "        \n",
    "    def reset(self):\n",
    "        self.paddle = pygame.Rect((WIDTH - PADDLE_WIDTH) // 2, HEIGHT - PADDLE_HEIGHT - 10, PADDLE_WIDTH, PADDLE_HEIGHT)\n",
    "        self.ball = pygame.Rect(WIDTH // 2 - BALL_RADIUS, HEIGHT // 2 - BALL_RADIUS, BALL_RADIUS * 2, BALL_RADIUS * 2)\n",
    "        self.bricks = [pygame.Rect(j * (BRICK_WIDTH + BRICK_SPACING), i * (BRICK_HEIGHT + BRICK_SPACING) + 50, BRICK_WIDTH, BRICK_HEIGHT)\n",
    "                       for i in range(BRICK_ROWS) for j in range(BRICK_COLS)]\n",
    "        self.ball_speed_x = BALL_SPEED_X * random.choice([1, -1])\n",
    "        self.ball_speed_y = BALL_SPEED_Y * random.choice([1, -1])\n",
    "        return self.get_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        reward = 0\n",
    "        if action == 0:  # 왼쪽으로 이동\n",
    "            self.paddle.x -= PADDLE_SPEED\n",
    "        elif action == 1:  # 오른쪽으로 이동\n",
    "            self.paddle.x += PADDLE_SPEED\n",
    "\n",
    "        self.ball.x += self.ball_speed_x\n",
    "        self.ball.y += self.ball_speed_y\n",
    "\n",
    "        if self.ball.left <= 0 or self.ball.right >= WIDTH:\n",
    "            self.ball_speed_x *= -1\n",
    "        if self.ball.top <= 0:\n",
    "            self.ball_speed_y *= -1\n",
    "\n",
    "        if self.ball.colliderect(self.paddle):\n",
    "            self.ball_speed_y *= -1\n",
    "            reward += 10\n",
    "\n",
    "        for brick in self.bricks[:]:\n",
    "            if self.ball.colliderect(brick):\n",
    "                self.bricks.remove(brick)\n",
    "                self.ball_speed_y *= -1\n",
    "                reward += 1\n",
    "\n",
    "        if self.ball.bottom >= HEIGHT:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        return self.get_state(), reward, done\n",
    "\n",
    "# 게임 환경 초기화\n",
    "game_env = Breakout()\n",
    "\n",
    "# 총 보상을 저장할 리스트\n",
    "total_rewards = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "for episode in range(20000):  # 적절한 에피소드 수를 선택해야 함\n",
    "    state = game_env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        # 게임 플레이 중지 판단\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                done = True\n",
    "                break\n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "        action = game_env.agent.choose_action(state)\n",
    "        next_state, reward, done = game_env.step(action)\n",
    "        game_env.agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        game_env.agent.replay(batch_size=2)  # 학습속도에 영향\n",
    "\n",
    "        # 게임 화면 그리기\n",
    "        screen.fill(BLACK)\n",
    "        pygame.draw.rect(screen, BLUE, game_env.paddle)\n",
    "        pygame.draw.circle(screen, YELLOW, game_env.ball.center, BALL_RADIUS)\n",
    "        for brick in game_env.bricks:\n",
    "            pygame.draw.rect(screen, WHITE, brick)\n",
    "        pygame.display.flip()\n",
    "        clock.tick(600000) # 게임 진행속도\n",
    "\n",
    "    total_rewards.append(total_reward)\n",
    "    print(f\"Episode: {episode + 1}, Total Reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.quit()\n",
    "# 학습 과정 시각화\n",
    "clear_output()\n",
    "plt.plot(total_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.title('Training Progress')\n",
    "plt.grid(True)\n",
    "plt.pause(0.01)  # 업데이트를 시각화하기 위해 잠시 멈춤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14 ('ffa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1530ed26bfae70f540aba00a5307c2c7e137b6bde89d5dc0f9017c7e8c3cd83b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
